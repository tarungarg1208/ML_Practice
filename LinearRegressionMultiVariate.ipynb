{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset=pd.read_csv('startup_data.csv')\n",
    "# x=dataset.iloc[:5,:-1]\n",
    "# y=dataset.iloc[:5,-1]\n",
    "# plt.scatter(dataset.iloc[:,0],dataset.iloc[:,-1])\n",
    "# print(x)\n",
    "# print(y)\n",
    "# x=x.values\n",
    "# y=y.values\n",
    "# # print(x)\n",
    "# # print(y)\n",
    "# print(y.shape)\n",
    "# m=x.shape[0]\n",
    "# n=x.shape[1]\n",
    "# x=np.concatenate((np.ones((m,1)),x),axis=1)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RESULTS.CSV \n",
    "# #w=gradient_descent(x,y,w,1000000,0.000000070)\n",
    "# dataset=pd.read_csv('results.csv',index_col=0)\n",
    "# x=dataset.iloc[:,:-1]\n",
    "# y=dataset.iloc[:,-1]\n",
    "# # plt.scatter(dataset.iloc[:,0],dataset.iloc[:,-1])\n",
    "# # print(x)\n",
    "# # print(y)\n",
    "# x=x.values\n",
    "# y=y.values\n",
    "# # print(x)\n",
    "# # print(y)\n",
    "# print(y.shape)\n",
    "# m=x.shape[0]\n",
    "# n=x.shape[1]\n",
    "# x=np.concatenate((np.ones((m,1)),x),axis=1)\n",
    "# sns.kdeplot(dataset[\"Sales\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 14)\n",
      "(380, 1)\n",
      "380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING BOSTON DATASET\n",
    "data=datasets.load_boston()\n",
    "target=pd.DataFrame(data.target,columns=[\"MEDV\"])\n",
    "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "# df.head()\n",
    "# target.head()\n",
    "x=df.iloc[:380,:]\n",
    "y=target[:380]\n",
    "x=x.values\n",
    "y=y.values\n",
    "m=x.shape[0]\n",
    "\n",
    "x=np.concatenate((np.ones((m,1)),x),axis=1)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(m)\n",
    "n=x.shape[1]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-212-18ea4ad436f3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-212-18ea4ad436f3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    np.dot(x[:,i],(y_pred-y)\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "np.dot(x[:,i],(y_pred-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 1)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x ,w).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "def cost(y,y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "\n",
    "\n",
    "def predictor(w,x):\n",
    "    return np.dot(x ,w)\n",
    "\n",
    "\n",
    "\n",
    "def gradient_helper(x,y,y_pred):\n",
    "    #PROBLEM\n",
    "    dw = np.zeros((n,1))\n",
    "    for i in range(n):\n",
    "       \n",
    "        \n",
    "        dw[i][0]=np.dot(x[:,i],(y_pred.reshape(-1,1)-y))/m\n",
    "        print(\"SHAPES\",y.shape)\n",
    "    return dw\n",
    "\n",
    "\n",
    "def gradient_descent(x,y,w,iteration,alpha):\n",
    "    for i in tqdm(range(iteration)):\n",
    "        y_pred=predictor(w,x)\n",
    "#         print(\"Y PREDICTED in \",i+1,\" th Iteration:\\n\",y_pred.shape,y_pred)\n",
    "        dw=gradient_helper(x,y,y_pred)\n",
    "        #print(\"DW in \",i+1,\" th Iteration:\\n\",dw)\n",
    "        #print(w.shape)\n",
    "        #print(dw.shape)\n",
    "        \n",
    "        w=w-(alpha*dw)\n",
    "        #print(\"check\",dw)\n",
    "        print(\"Cost in \",i+1,\" th Iteration:\",cost(y,y_pred))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a1d8c1bb454985b27bf84a055bf079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  1  th Iteration: 704.412\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  2  th Iteration: 553.7599982001379\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  3  th Iteration: 440.347283078565\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  4  th Iteration: 354.95903050544746\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  5  th Iteration: 290.66069491684664\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  6  th Iteration: 242.23373631394014\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  7  th Iteration: 205.75098109332674\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  8  th Iteration: 178.25706320898706\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  9  th Iteration: 157.52794270407236\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "SHAPES (380, 1)\n",
      "Cost in  10  th Iteration: 141.88993328991717\n",
      "[[7.29588507e-05]\n",
      " [4.26373942e-05]\n",
      " [1.45225646e-03]\n",
      " [5.49624042e-04]\n",
      " [8.00124240e-06]\n",
      " [3.66790036e-05]\n",
      " [4.89491899e-04]\n",
      " [4.22079831e-03]\n",
      " [3.22630946e-04]\n",
      " [3.94345359e-04]\n",
      " [2.28464898e-02]\n",
      " [1.26281156e-03]\n",
      " [2.79308044e-02]\n",
      " [5.85827268e-04]]\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "#MAIN\n",
    "#Number of Rows and Columns\n",
    "# m=x.shape[0]\n",
    "n=x.shape[1]\n",
    "w=np.zeros((n,1))\n",
    "print(w)\n",
    "w=gradient_descent(x,y,w,10,0.0000005)\n",
    "print(w)\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUM OF RESIDUALS= 2468.8901626785546\n",
      "MSE= 130.08351298636637\n",
      "RMSE= 11.405415949730477\n"
     ]
    }
   ],
   "source": [
    "y_pred=predictor(w,x)\n",
    "res=y-y_pred\n",
    "mse=(res**2).mean()\n",
    "print(\"SUM OF RESIDUALS=\",res.sum())\n",
    "print(\"MSE=\",mse)\n",
    "print(\"RMSE=\",mse**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE= 11.58001653483575\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   74.97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 27 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>1.23e-94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:20:31</td>     <th>  Log-Likelihood:    </th> <td> -1119.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   380</td>      <th>  AIC:               </th> <td>   2267.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   366</td>      <th>  BIC:               </th> <td>   2322.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   23.8818</td> <td>    6.090</td> <td>    3.921</td> <td> 0.000</td> <td>   11.905</td> <td>   35.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.2783</td> <td>    0.159</td> <td>   -1.745</td> <td> 0.082</td> <td>   -0.592</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0459</td> <td>    0.014</td> <td>    3.317</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0687</td> <td>    0.064</td> <td>    1.071</td> <td> 0.285</td> <td>   -0.057</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.9126</td> <td>    0.889</td> <td>    1.026</td> <td> 0.305</td> <td>   -0.836</td> <td>    2.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -15.2804</td> <td>    4.463</td> <td>   -3.424</td> <td> 0.001</td> <td>  -24.057</td> <td>   -6.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    5.2842</td> <td>    0.485</td> <td>   10.906</td> <td> 0.000</td> <td>    4.331</td> <td>    6.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0014</td> <td>    0.014</td> <td>   -0.102</td> <td> 0.919</td> <td>   -0.029</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.3178</td> <td>    0.209</td> <td>   -6.307</td> <td> 0.000</td> <td>   -1.729</td> <td>   -0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.6337</td> <td>    0.104</td> <td>    6.112</td> <td> 0.000</td> <td>    0.430</td> <td>    0.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0145</td> <td>    0.004</td> <td>   -3.339</td> <td> 0.001</td> <td>   -0.023</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.8124</td> <td>    0.137</td> <td>   -5.919</td> <td> 0.000</td> <td>   -1.082</td> <td>   -0.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0019</td> <td>    0.007</td> <td>    0.288</td> <td> 0.773</td> <td>   -0.011</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.4556</td> <td>    0.064</td> <td>   -7.084</td> <td> 0.000</td> <td>   -0.582</td> <td>   -0.329</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>87.628</td> <th>  Durbin-Watson:     </th> <td>   1.130</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 478.004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.844</td> <th>  Prob(JB):          </th> <td>1.60e-104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.229</td> <th>  Cond. No.          </th> <td>1.46e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.46e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.727\n",
       "Model:                            OLS   Adj. R-squared:                  0.717\n",
       "Method:                 Least Squares   F-statistic:                     74.97\n",
       "Date:                Tue, 27 Aug 2019   Prob (F-statistic):           1.23e-94\n",
       "Time:                        11:20:31   Log-Likelihood:                -1119.4\n",
       "No. Observations:                 380   AIC:                             2267.\n",
       "Df Residuals:                     366   BIC:                             2322.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         23.8818      6.090      3.921      0.000      11.905      35.858\n",
       "x1            -0.2783      0.159     -1.745      0.082      -0.592       0.035\n",
       "x2             0.0459      0.014      3.317      0.001       0.019       0.073\n",
       "x3             0.0687      0.064      1.071      0.285      -0.057       0.195\n",
       "x4             0.9126      0.889      1.026      0.305      -0.836       2.661\n",
       "x5           -15.2804      4.463     -3.424      0.001     -24.057      -6.504\n",
       "x6             5.2842      0.485     10.906      0.000       4.331       6.237\n",
       "x7            -0.0014      0.014     -0.102      0.919      -0.029       0.026\n",
       "x8            -1.3178      0.209     -6.307      0.000      -1.729      -0.907\n",
       "x9             0.6337      0.104      6.112      0.000       0.430       0.838\n",
       "x10           -0.0145      0.004     -3.339      0.001      -0.023      -0.006\n",
       "x11           -0.8124      0.137     -5.919      0.000      -1.082      -0.542\n",
       "x12            0.0019      0.007      0.288      0.773      -0.011       0.015\n",
       "x13           -0.4556      0.064     -7.084      0.000      -0.582      -0.329\n",
       "==============================================================================\n",
       "Omnibus:                       87.628   Durbin-Watson:                   1.130\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              478.004\n",
       "Skew:                           0.844   Prob(JB):                    1.60e-104\n",
       "Kurtosis:                       8.229   Cond. No.                     1.46e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.46e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model=sm.OLS(y,x).fit()\n",
    "predictions=model.predict(x)\n",
    "\n",
    "residual=predictions-y\n",
    "\n",
    "print(\"RMSE=\",(((predictions-y)**2).mean())**0.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset=pd.read_csv('startup_data.csv')\n",
    "# x=dataset.iloc[:,:-1]\n",
    "# y=dataset.iloc[:,-1]\n",
    "# import statsmodels.api as sm\n",
    "# model=sm.OLS(y,x).fit()\n",
    "# predictions=model.predict(x)\n",
    "# residual=predictions-y\n",
    "# print(\"MSE=\",(((predictions-y)**2).mean()))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 135.0733891015487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.969</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.968</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   872.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 27 Aug 2019</td> <th>  Prob (F-statistic):</th>          <td>1.09e-266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:15</td>     <th>  Log-Likelihood:    </th>          <td> -1127.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   380</td>      <th>  AIC:               </th>          <td>   2281.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   367</td>      <th>  BIC:               </th>          <td>   2332.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>   -0.3050</td> <td>    0.162</td> <td>   -1.878</td> <td> 0.061</td> <td>   -0.624</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>    0.0469</td> <td>    0.014</td> <td>    3.321</td> <td> 0.001</td> <td>    0.019</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.0570</td> <td>    0.065</td> <td>    0.872</td> <td> 0.384</td> <td>   -0.072</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>    0.8696</td> <td>    0.906</td> <td>    0.960</td> <td> 0.338</td> <td>   -0.912</td> <td>    2.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>   -5.0846</td> <td>    3.698</td> <td>   -1.375</td> <td> 0.170</td> <td>  -12.356</td> <td>    2.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>    6.4779</td> <td>    0.384</td> <td>   16.857</td> <td> 0.000</td> <td>    5.722</td> <td>    7.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>   -0.0071</td> <td>    0.014</td> <td>   -0.492</td> <td> 0.623</td> <td>   -0.035</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -1.0320</td> <td>    0.200</td> <td>   -5.170</td> <td> 0.000</td> <td>   -1.425</td> <td>   -0.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.5570</td> <td>    0.104</td> <td>    5.366</td> <td> 0.000</td> <td>    0.353</td> <td>    0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   -0.0122</td> <td>    0.004</td> <td>   -2.781</td> <td> 0.006</td> <td>   -0.021</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   -0.5215</td> <td>    0.118</td> <td>   -4.430</td> <td> 0.000</td> <td>   -0.753</td> <td>   -0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0123</td> <td>    0.006</td> <td>    2.037</td> <td> 0.042</td> <td>    0.000</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -0.3945</td> <td>    0.064</td> <td>   -6.201</td> <td> 0.000</td> <td>   -0.520</td> <td>   -0.269</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>98.200</td> <th>  Durbin-Watson:     </th> <td>   1.104</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 883.413</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.800</td> <th>  Prob(JB):          </th> <td>1.48e-192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.296</td> <th>  Cond. No.          </th> <td>7.77e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.969\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.968\n",
       "Method:                 Least Squares   F-statistic:                              872.0\n",
       "Date:                Tue, 27 Aug 2019   Prob (F-statistic):                   1.09e-266\n",
       "Time:                        10:22:15   Log-Likelihood:                         -1127.3\n",
       "No. Observations:                 380   AIC:                                      2281.\n",
       "Df Residuals:                     367   BIC:                                      2332.\n",
       "Df Model:                          13                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.3050      0.162     -1.878      0.061      -0.624       0.014\n",
       "x2             0.0469      0.014      3.321      0.001       0.019       0.075\n",
       "x3             0.0570      0.065      0.872      0.384      -0.072       0.185\n",
       "x4             0.8696      0.906      0.960      0.338      -0.912       2.652\n",
       "x5            -5.0846      3.698     -1.375      0.170     -12.356       2.187\n",
       "x6             6.4779      0.384     16.857      0.000       5.722       7.234\n",
       "x7            -0.0071      0.014     -0.492      0.623      -0.035       0.021\n",
       "x8            -1.0320      0.200     -5.170      0.000      -1.425      -0.639\n",
       "x9             0.5570      0.104      5.366      0.000       0.353       0.761\n",
       "x10           -0.0122      0.004     -2.781      0.006      -0.021      -0.004\n",
       "x11           -0.5215      0.118     -4.430      0.000      -0.753      -0.290\n",
       "x12            0.0123      0.006      2.037      0.042       0.000       0.024\n",
       "x13           -0.3945      0.064     -6.201      0.000      -0.520      -0.269\n",
       "==============================================================================\n",
       "Omnibus:                       98.200   Durbin-Watson:                   1.104\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              883.413\n",
       "Skew:                           0.800   Prob(JB):                    1.48e-192\n",
       "Kurtosis:                      10.296   Cond. No.                     7.77e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.77e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x=dataset.iloc[:,:-1]\n",
    "# y=dataset.iloc[:,-1]\n",
    "import statsmodels.api as sm\n",
    "model=sm.OLS(y,x).fit()\n",
    "predictions=model.predict(x)\n",
    "residual=predictions-y\n",
    "print(\"MSE=\",(((predictions-y)**2).mean()))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
